# Ralph Progress Log

## Codebase Patterns

(Add reusable patterns discovered during iterations here)

---

## Log

(Iteration entries will be appended below)

---

## 2026-01-22 - US-001

**Story:** Create ReviewerConfig Pydantic model

### What was implemented
- Created `ReviewerLevel` enum with three values: `blocking`, `warning`, `suggestion`
- Created `ReviewerConfig` Pydantic model with fields:
  - `name`: Display name of the reviewer
  - `skill`: Skill path to invoke for this reviewer
  - `level`: Severity level (ReviewerLevel enum)
  - `languages`: Optional list of strings for language filtering (defaults to None)
- Exported both models from `ralph.models` module

### Tests written
- `TestReviewerLevel`: 5 tests verifying enum values and string comparison behavior
- `TestReviewerConfig`: 11 tests covering:
  - Model creation with all fields
  - Default value for languages (None)
  - Multiple languages support
  - Empty languages list handling
  - Level field accepting string values that map to enum
  - Required field validation (name, skill, level)
  - Invalid level value handling
  - Model serialization (model_dump)
  - Model creation from dict (model_validate)

### Files changed
- `src/ralph/models/reviewer.py` (new)
- `src/ralph/models/__init__.py` (updated exports)
- `tests/test_reviewer_config.py` (new)

### Learnings for future iterations
- `str, Enum` pattern allows enum values to be compared directly with strings using `==`
- When testing `str(EnumValue)`, it returns the full enum name (e.g., `ReviewerLevel.blocking`), not just the value
- Follow existing model patterns: use `Field(...)` for required fields, `Field(default=...)` for optional

---

## 2026-01-22 - US-002

**Story:** Implement reviewer configuration parsing from CLAUDE.md

### What was implemented
- Created `ReviewerConfigs` container model to hold list of `ReviewerConfig` objects
- Created `_REVIEWERS_PATTERN` regex to match RALPH:REVIEWERS markers (consistent with checks pattern)
- Implemented `get_default_reviewers()` function returning default reviewer configuration:
  - test-quality, code-simplifier, python-code as blocking
  - github-actions, repo-structure as warning
  - release as blocking
  - python-code filtered to python language
- Implemented `parse_reviewer_configs(content: str)` function:
  - Extracts YAML from between markers
  - Returns list of ReviewerConfig objects
  - Returns default reviewers when markers missing or content malformed
- Implemented `load_reviewer_configs(path: Path)` function:
  - Loads CLAUDE.md file and delegates to parse function
  - Returns defaults if file doesn't exist
- Exported all new functions and classes from `ralph.models` module

### Tests written
- `TestReviewerConfigs`: 2 tests for container model
- `TestGetDefaultReviewers`: 4 tests verifying default configuration
- `TestParseReviewerConfigs`: 8 tests covering:
  - Valid reviewers block parsing
  - Missing markers returns defaults
  - Languages filter parsing
  - Malformed YAML returns defaults
  - Invalid structure returns defaults
  - Empty list returns defaults
  - All severity levels parsed correctly
- `TestLoadReviewerConfigs`: 3 tests for file loading

### Files changed
- `src/ralph/models/reviewer.py` (extended with parsing functions)
- `src/ralph/models/__init__.py` (updated exports)
- `tests/test_reviewer_config.py` (added 17 new tests)

### Learnings for future iterations
- Follow the exact pattern from config.py when adding new YAML-based parsing
- Container models (like ReviewerConfigs) are useful for Pydantic validation of YAML structures
- Return defaults for any error case (missing markers, malformed YAML, empty list) for robustness

---

[Ralph Loop] 2026-01-21 22:10 UTC - Iteration 1: US-001 (Create ReviewerConfig Pydantic model) completed
[Ralph Loop] 2026-01-22 - Iteration 2: US-002 (Implement reviewer configuration parsing from CLAUDE.md) completed

[Ralph Loop] 2026-01-21 22:13 UTC - Iteration 2: US-002 (Implement reviewer configuration parsing from CLAUDE.md) completed

---

## 2026-01-22 - US-003

**Story:** Implement language detection service

### What was implemented
- Created `Language` enum with values: `python`, `javascript`, `typescript`, `go`, `rust`
- Created `LanguageDetector` Pydantic model service with:
  - `project_root`: Path to the project directory
  - `detect()`: Returns set of detected languages
  - `has_language()`: Checks if specific language is detected
- Defined marker file mappings:
  - Python: `pyproject.toml`, `setup.py`, `requirements.txt`
  - JavaScript: `package.json`
  - TypeScript: `tsconfig.json`
  - Go: `go.mod`
  - Rust: `Cargo.toml`
- Created `detect_languages()` convenience function for quick detection
- Exported `Language`, `LanguageDetector`, and `detect_languages` from `ralph.services` module

### Tests written
- `TestLanguageEnum`: 7 tests verifying enum values and string comparison
- `TestLanguageDetectorPython`: 4 tests for Python detection from all marker files
- `TestLanguageDetectorJavaScript`: 3 tests for JS/TS detection
- `TestLanguageDetectorGo`: 2 tests for Go detection
- `TestLanguageDetectorRust`: 2 tests for Rust detection
- `TestLanguageDetectorMultiple`: 2 tests for multiple language detection
- `TestLanguageDetectorNoLanguages`: 2 tests for empty/unknown project scenarios
- `TestDetectLanguagesFunction`: 3 tests for convenience function
- `TestLanguageDetectorModel`: 3 tests for Pydantic model behavior

Total: 28 new tests

### Files changed
- `src/ralph/services/language.py` (new)
- `src/ralph/services/__init__.py` (updated exports)
- `tests/test_language_detection.py` (new)

### Learnings for future iterations
- Services can be simple Pydantic models with methods, similar to GitService pattern
- Use `ConfigDict(arbitrary_types_allowed=True)` for Path fields in Pydantic models
- Language detection is file-existence based, not content-based - keeps it fast and simple

---

[Ralph Loop] 2026-01-22 - Iteration 3: US-003 (Implement language detection service) completed

[Ralph Loop] 2026-01-21 22:16 UTC - Iteration 3: US-003 (Implement language detection service) completed

---

## 2026-01-22 - US-004

**Story:** Add --skip-review and --strict flags to ralph loop

### What was implemented
- Added `--skip-review` flag to loop command (defaults to False)
- Added `--strict` flag to loop command (defaults to False)
- Updated command docstring to describe the new flags and their behavior
- Added debug logging to show flag values when all stories complete
- Prepared integration point for US-006 where review loop will be connected

### Tests written
- `test_loop_accepts_skip_review_flag`: Verifies the flag is accepted and loop completes successfully
- `test_loop_accepts_strict_flag`: Verifies the flag is accepted and loop completes successfully
- `test_loop_accepts_both_skip_review_and_strict_flags`: Verifies both flags work together
- `test_loop_help_shows_skip_review_flag`: Verifies help text shows flag and description
- `test_loop_help_shows_strict_flag`: Verifies help text shows flag and description

### Files changed
- `src/ralph/commands/loop.py` (added flags and documentation)
- `tests/test_commands_integration.py` (added 5 new tests)
- `plans/TASKS.json` (marked US-004 as passes: true)

### Learnings for future iterations
- Typer help text can wrap across multiple lines, so tests should check for key phrases rather than full sentences
- Future stories (US-005, US-006) will implement the actual review loop; this story just adds the CLI interface
