# Ralph Progress Log

## Codebase Patterns

(Add reusable patterns discovered during iterations here)

---

## Log

(Iteration entries will be appended below)

---

## 2026-02-08 - US-001

**Story:** Add --no-fix flag to review commands

### What was implemented
- Added `--no-fix` boolean flag (default: False) to the `loop()` command in `src/ralph/commands/loop.py`
- Added `--no-fix` boolean flag (default: False) to the `review()` command in `src/ralph/commands/review.py`
- Threaded `no_fix` parameter through `_run_review_loop()` in `loop.py` (signature + call site)
- Help text: "Report review findings without applying automated fixes"

### Tests written
- No new tests needed for this story (flag plumbing only; behavior implementation is US-002)
- All 217 existing tests pass

### Files changed
- `src/ralph/commands/loop.py` - added `no_fix` param to `loop()` and `_run_review_loop()`
- `src/ralph/commands/review.py` - added `no_fix` param to `review()`
- `plans/TASKS.json` - marked US-001 as passes: true

### Learnings for future iterations
- Typer `--no-fix` automatically maps to `no_fix` Python parameter via Typer's flag naming convention
- The `_run_review_loop()` function in loop.py is the bridge between the loop command and the review pipeline; subsequent stories (US-002, US-003) will wire no_fix into ReviewLoopService

---

[Ralph Loop] 2026-02-08 05:55 UTC - Iteration 1: US-001 (Add --no-fix flag to review commands) completed

## 2026-02-08 - US-002

**Story:** Implement --no-fix behavior in ReviewLoopService

### What was implemented
- Added `no_fix` keyword parameter (default: False) to `ReviewLoopService.run_review_loop()` method signature
- When `no_fix=True`, the `FixLoopService.run_fix_loop()` call is skipped after a NEEDS_WORK verdict
- Logs `[Fix] Skipped (--no-fix)` via `logger.info()` when a fix is skipped
- Continues to the next reviewer after logging (pipeline is not aborted)

### Tests written
- `test_no_fix_skips_fix_loop_on_needs_work` - verifies FixLoopService is not instantiated when no_fix=True
- `test_no_fix_logs_skip_message` - verifies '[Fix] Skipped (--no-fix)' appears in log records
- `test_no_fix_continues_to_next_reviewer` - verifies both reviewers in a 2-reviewer pipeline execute when no_fix=True
- `test_no_fix_false_still_runs_fix_loop` - verifies default behavior (no_fix=False) still invokes fix loop

### Files changed
- `src/ralph/services/review_loop.py` - added `no_fix` param to `run_review_loop()`, conditional skip of fix loop
- `tests/test_review_loop.py` - added 4 new tests, `logging` and `pytest` imports
- `plans/TASKS.json` - marked US-002 as passes: true

### Learnings for future iterations
- The commands (loop.py, review.py) currently iterate reviewers manually rather than calling `run_review_loop()`. Future stories (US-003) that add no_fix summary output to commands will need to handle this in both places.
- `caplog` fixture with `caplog.at_level(logging.INFO)` is the clean way to assert log messages in tests.

---

[Ralph Loop] 2026-02-08 05:58 UTC - Iteration 2: US-002 (Implement --no-fix behavior in ReviewLoopService) completed

## 2026-02-08 - US-003

**Story:** Add --no-fix summary to review output

### What was implemented
- Added `fix_skipped` field (default: False) to `ReviewerResult` NamedTuple in `review_loop.py`
- In `ReviewLoopService.run_review_loop()`, set `fix_skipped=True` on results when `no_fix=True` and reviewer has NEEDS_WORK findings eligible for fix loop
- Updated summary display in `_run_review_loop()` in `loop.py` to show `[FINDINGS] reviewer: findings (not fixed)` for fix-skipped reviewers
- Updated summary display in `review()` in `review.py` with the same logic
- Both summaries include `Findings (not fixed): N` count in the summary line when skipped_fix > 0
- Both commands detect `no_fix` + NEEDS_WORK + eligible fix loop and mark results with `fix_skipped=True`

### Tests written
- `TestNoFixSummary::test_no_fix_sets_fix_skipped_on_needs_work_result` - verifies fix_skipped=True on NEEDS_WORK results in run_review_loop
- `TestNoFixSummary::test_no_fix_does_not_set_fix_skipped_on_passed_result` - verifies fix_skipped=False on PASSED results
- `TestNoFixSummary::test_no_fix_false_does_not_set_fix_skipped` - verifies default behavior leaves fix_skipped=False
- `TestNoFixSummary::test_no_fix_mixed_results_only_marks_needs_work` - verifies only NEEDS_WORK reviewers get fix_skipped
- `TestReviewNoFixSummary::test_no_fix_shows_findings_not_fixed_in_summary` - verifies CLI output shows "findings (not fixed)"
- `TestReviewNoFixSummary::test_no_fix_includes_skipped_fix_count_in_summary_line` - verifies "Findings (not fixed): 1" in summary line
- `TestReviewNoFixSummary::test_no_fix_not_set_does_not_show_findings_not_fixed` - verifies no spurious output without --no-fix

### Files changed
- `src/ralph/services/review_loop.py` - added `fix_skipped` field to ReviewerResult, set it in run_review_loop()
- `src/ralph/commands/loop.py` - added Verdict import, no_fix-aware result marking, updated summary display
- `src/ralph/commands/review.py` - added Verdict import, no_fix-aware result marking, updated summary display
- `tests/test_review_loop.py` - added TestNoFixSummary class with 4 tests
- `tests/test_review_command.py` - added TestReviewNoFixSummary class with 3 tests, updated _make_mock_service()
- `plans/TASKS.json` - marked US-003 as passes: true

### Learnings for future iterations
- Both `loop.py::_run_review_loop()` and `review.py::review()` manually iterate reviewers rather than calling `ReviewLoopService.run_review_loop()`, so changes to summary display must be made in both places
- NamedTuple fields with defaults must come after fields without defaults; `fix_skipped: bool = False` works at the end
- When using MagicMock for ReviewerResult in integration tests, auto-generated attributes (like fix_skipped) return MagicMock objects which are truthy â€” switching to real ReviewerResult instances avoids this

---

[Ralph Loop] 2026-02-08 06:04 UTC - Iteration 3: US-003 (Add --no-fix summary to review output) completed

## 2026-02-08 - US-004

**Story:** Create ReviewState Pydantic model

### What was implemented
- Created `ReviewState` Pydantic model in `src/ralph/models/review_state.py` with fields: `reviewer_names`, `completed`, `timestamp`, `config_hash`
- Added `compute_config_hash()` static method that produces a deterministic SHA-256 hash from a list of `ReviewerConfig` objects (captures name, skill, level, sorted languages)
- Added `save()` instance method to write state to a JSON file
- Added `load()` class method to read state from a JSON file (returns `None` for missing/invalid files)
- Added `REVIEW_STATE_FILENAME` constant (`.ralph-review-state.json`)
- Exported `ReviewState` and `REVIEW_STATE_FILENAME` from `src/ralph/models/__init__.py`

### Tests written
- `TestReviewStateModel::test_create_review_state` - verifies model creation with all fields
- `TestReviewStateModel::test_completed_defaults_to_empty_dict` - verifies default factory
- `TestReviewStateModel::test_serialization_round_trip` - verifies JSON serialization/deserialization
- `TestComputeConfigHash::test_hash_is_deterministic` - same config produces same hash
- `TestComputeConfigHash::test_hash_is_hex_string` - valid 64-char hex digest
- `TestComputeConfigHash::test_hash_changes_with_different_config` - different configs differ
- `TestComputeConfigHash::test_hash_changes_when_level_changes` - level change detected
- `TestComputeConfigHash::test_hash_empty_list` - empty list produces valid hash
- `TestComputeConfigHash::test_hash_language_order_irrelevant` - language list order normalized
- `TestSaveAndLoad::test_save_creates_json_file` - file written with correct content
- `TestSaveAndLoad::test_load_valid_file` - valid file loaded correctly
- `TestSaveAndLoad::test_load_nonexistent_returns_none` - missing file returns None
- `TestSaveAndLoad::test_load_invalid_json_returns_none` - malformed JSON returns None
- `TestSaveAndLoad::test_load_invalid_schema_returns_none` - wrong schema returns None
- `TestSaveAndLoad::test_save_load_round_trip` - save and load are inverse operations
- `TestReviewStateFilename::test_filename_value` - constant has expected value

### Files changed
- `src/ralph/models/review_state.py` - new file, ReviewState model
- `src/ralph/models/__init__.py` - added ReviewState and REVIEW_STATE_FILENAME exports
- `tests/test_review_state.py` - new file, 16 tests
- `plans/TASKS.json` - marked US-004 as passes: true

### Learnings for future iterations
- The manifest model (`manifest.py`) uses `by_alias=True` for camelCase JSON, but ReviewState uses snake_case throughout since `.ralph-review-state.json` is internal-only
- `compute_config_hash` sorts languages to ensure order-independence; this is important since `ReviewerConfig.languages` is a plain list
- Follow the `load`/`save` pattern from `manifest.py` for consistency: `load` returns `None` on failure, `save` writes with trailing newline

---

[Ralph Loop] 2026-02-08 - Iteration 4: US-004 (Create ReviewState Pydantic model) completed
